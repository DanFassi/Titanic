{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226e94b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score,StratifiedKFold\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (GradientBoostingClassifier,RandomForestClassifier, VotingClassifier,\n",
    "                             StackingClassifier, AdaBoostClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c18fe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_processed.csv\")\n",
    "y = df[\"Survived\"]\n",
    "X = df.iloc[:,2:]\n",
    "#X = X.drop([\"Ticket_number\"], axis =1)\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f3ef497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sex', 'Age', 'Ticket_category', 'Is_with_familly', 'Fare_per_person',\n",
       "       'Pclass_1', 'Pclass_2', 'Pclass_3', 'SibSp_0', 'SibSp_1', 'SibSp_2',\n",
       "       'Parch_0', 'Parch_1', 'Parch_2', 'Embarked_C', 'Embarked_Q',\n",
       "       'Embarked_S'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1ce091",
   "metadata": {},
   "source": [
    "# Modelisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373944fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc\n",
      "best parameters : {'C': 0.5, 'kernel': 'rbf'}\n",
      "TRAIN accuracy : 0.8062050625430908\n",
      "TEST accuracy : 0.7988826815642458 \n",
      "\n",
      "knn\n",
      "best parameters : {'metric': 'minkowski', 'n_neighbors': 15}\n",
      "TRAIN accuracy : 0.7765882005318625\n",
      "TEST accuracy : 0.8044692737430168 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rl\n",
      "best parameters : {'C': 0.07, 'max_iter': 300, 'solver': 'newton-cg'}\n",
      "TRAIN accuracy : 0.8047473653107456\n",
      "TEST accuracy : 0.7821229050279329 \n",
      "\n",
      "gb\n",
      "best parameters : {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100}\n",
      "TRAIN accuracy : 0.8243967300305328\n",
      "TEST accuracy : 0.8268156424581006 \n",
      "\n",
      "rf\n",
      "best parameters : {'criterion': 'entropy', 'max_depth': None, 'max_features': None}\n",
      "TRAIN accuracy : 0.8272727272727274\n",
      "TEST accuracy : 0.7932960893854749 \n",
      "\n",
      "dt\n",
      "best parameters : {'criterion': 'gini', 'max_depth': 3, 'max_features': None}\n",
      "TRAIN accuracy : 0.806155816014971\n",
      "TEST accuracy : 0.7877094972067039 \n",
      "\n",
      "gnb\n",
      "best parameters : {}\n",
      "TRAIN accuracy : 0.7443809711415346\n",
      "TEST accuracy : 0.7318435754189944 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "models = [SVC(), KNeighborsClassifier(),LogisticRegression(),GradientBoostingClassifier(),RandomForestClassifier(),\n",
    "          DecisionTreeClassifier(), GaussianNB()]\n",
    "names = [\"svc\",\"knn\",\"rl\",\"gb\",\"rf\",\"dt\",\"gnb\"]\n",
    "param_grid_svc = {'C':[0.5,1,5,10],\"kernel\" :[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],}\n",
    "param_grid_knn = {'n_neighbors':[5,15,25],\"metric\" :[\"minkowski\",\"euclidean\",\"manhattan\",\"chebyshev\"]}\n",
    "param_grid_rl = { 'C':[0.05,0.07,0.1], 'max_iter' : [300,200,100], \"solver\" : [\"newton-cg\", \"lbfgs\", \"sag\", \"saga\"]}\n",
    "param_grid_gb = {\"n_estimators\":[100,200,300], \"learning_rate\":[0.10,0.50,1], \"max_depth\": [1,2,3]}\n",
    "param_grid_rf = {'max_features': [\"sqrt\", \"log2\", None], \"criterion\": [\"gini\", \"entropy\"],\"max_depth\" : [3,2,1, None]}\n",
    "param_grid_dt = {'max_features': [\"sqrt\", \"log2\", None], \"criterion\": [\"gini\", \"entropy\"],\"max_depth\" : [3,2,1, None]}\n",
    "param_grid_gnb = {}\n",
    "param_grid = [param_grid_svc,param_grid_knn,param_grid_rl,param_grid_gb,param_grid_rf,param_grid_dt,param_grid_gnb]\n",
    "\n",
    "gridcvs = {}\n",
    "for pgrid, clf, name in zip(param_grid,models,names):\n",
    "    gcv = GridSearchCV(clf, pgrid, cv=5, n_jobs= -1, refit=True).fit(X_train,y_train)\n",
    "    gridcvs[name] = gcv\n",
    "    print(name)\n",
    "    print(\"best parameters :\",gridcvs[name].best_params_)\n",
    "    print(\"TRAIN accuracy :\", gridcvs[name].best_score_)\n",
    "    print(\"TEST accuracy :\", gridcvs[name].score(X_test,y_test),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278aad29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'poly'}\n",
      "0.8047473653107456\n",
      "svc test score : 0.8100558659217877\n"
     ]
    }
   ],
   "source": [
    "svc = SVC()\n",
    "param_grid_svc = {'C':[1,5,10],\"kernel\" :[\"linear\", \"poly\", \"rbf\", \"sigmoid\"],}\n",
    "grid_svc = GridSearchCV(estimator=svc, param_grid= param_grid_svc,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_svc.best_params_)\n",
    "print(grid_svc.best_score_) \n",
    "print(\"svc test score :\",grid_svc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98311f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'minkowski', 'n_neighbors': 15}\n",
      "0.7765882005318625\n",
      "knn test  score : 0.8044692737430168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "knn =  KNeighborsClassifier()\n",
    "param_grid_knn = {'n_neighbors':[5,10,15,20,25,30],\"metric\" :[\"minkowski\",\"euclidean\",\"manhattan\",\"chebyshev\"]}\n",
    "grid_knn = GridSearchCV(estimator=knn, param_grid= param_grid_knn,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_knn.best_params_)\n",
    "print(grid_knn.best_score_) \n",
    "print(\"knn test  score :\",grid_knn.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7dd655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.07, 'max_iter': 300, 'solver': 'newton-cg'}\n",
      "0.8047473653107456\n",
      "rl test score : 0.7821229050279329\n"
     ]
    }
   ],
   "source": [
    "rl = LogisticRegression()\n",
    "param_grid_rl = { 'C':[0.05,0.07,0.1], 'max_iter' : [300,200,100], \"solver\" : [\"newton-cg\", \"lbfgs\", \"sag\", \"saga\"]}\n",
    "grid_rl = GridSearchCV(estimator=rl, param_grid= param_grid_rl,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_rl.best_params_)\n",
    "print(grid_rl.best_score_) \n",
    "print(\"rl test score :\",grid_rl.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "541ffd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.25, 'max_depth': 2, 'n_estimators': 300}\n",
      "0.8272530286614794\n",
      "gb test score : 0.8435754189944135\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "param_grid_gb = {\"n_estimators\":[100,200,300], \"learning_rate\":[0.25,0.30,0.40], \"max_depth\": [1,2]}\n",
    "grid_gb = GridSearchCV(estimator=gb, param_grid= param_grid_gb,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_gb.best_params_)\n",
    "print(grid_gb.best_score_) \n",
    "print(\"gb test score :\",grid_gb.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af7385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ea470f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt'}\n",
      "0.8328868314783808\n",
      "rf test score : 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "param_grid_rf = {'max_features': [\"sqrt\", \"log2\", None], \"criterion\": [\"gini\", \"entropy\"],\"max_depth\" : [2,1, None]}\n",
    "grid_rf = GridSearchCV(estimator=rf, param_grid= param_grid_rf,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_rf.best_params_)\n",
    "print(grid_rf.best_score_) \n",
    "print(\"rf test score :\",grid_rf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e307b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': None, 'max_features': None}\n",
      "0.8357135821924555\n",
      "dt test score : 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "param_grid_dt = {'max_features': [\"sqrt\", \"log2\", None], \"criterion\": [\"gini\", \"entropy\"],\"max_depth\" : [2,1, None]}\n",
    "grid_dt = GridSearchCV(estimator=rf, param_grid= param_grid_rf,cv=5, n_jobs = -1, refit=True).fit(X_train,y_train)\n",
    "print(grid_dt.best_params_)\n",
    "print(grid_dt.best_score_) \n",
    "print(\"dt test score :\",grid_dt.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe6e1833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>0.289604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_number</th>\n",
       "      <td>0.219401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.162077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare_per_person</th>\n",
       "      <td>0.130980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>0.076498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket_category</th>\n",
       "      <td>0.026129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp_2</th>\n",
       "      <td>0.024170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Is_with_familly</th>\n",
       "      <td>0.017090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch_2</th>\n",
       "      <td>0.016110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.011563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0.008162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp_0</th>\n",
       "      <td>0.005626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SibSp_1</th>\n",
       "      <td>0.005479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.002975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0.002140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch_0</th>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Parch_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Importance\n",
       "Sex                0.289604\n",
       "Ticket_number      0.219401\n",
       "Age                0.162077\n",
       "Fare_per_person    0.130980\n",
       "Pclass_3           0.076498\n",
       "Ticket_category    0.026129\n",
       "SibSp_2            0.024170\n",
       "Is_with_familly    0.017090\n",
       "Parch_2            0.016110\n",
       "Embarked_Q         0.011563\n",
       "Pclass_1           0.008162\n",
       "SibSp_0            0.005626\n",
       "SibSp_1            0.005479\n",
       "Embarked_C         0.002975\n",
       "Pclass_2           0.002140\n",
       "Parch_0            0.001998\n",
       "Parch_1            0.000000\n",
       "Embarked_S         0.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats={}\n",
    "dt2=DecisionTreeClassifier(criterion= 'gini', max_depth= None, max_features= None)\n",
    "dt2.fit(X_train,y_train)\n",
    "for feature, importance in zip(X_train.columns, dt2.feature_importances_):\n",
    "    feats[feature] = importance \n",
    "    \n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Importance'})\n",
    "importances.sort_values(by='Importance', ascending=False).head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10184397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vclf_all test score : 0.8212290502793296\n",
      "vclf_best test score : 0.8379888268156425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dan\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    }
   ],
   "source": [
    "vclf_all = VotingClassifier(estimators=[('gb', gb), ('rf', rf), ('svc', svc), ('lr', rl), (\"knn\",knn),(\"dt\",dt)], voting='hard').fit(X_train,y_train)\n",
    "vclf_best = VotingClassifier(estimators=[('gb', gb), ('rf', rf),(\"dt\",dt)], voting='hard').fit(X_train,y_train)\n",
    "print(\"vclf_all test score :\", vclf_all.score(X_test,y_test))\n",
    "print(\"vclf_best test score :\", vclf_best.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4acfd732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sclf test score : 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "sclf = StackingClassifier(estimators=[('gb', gb), ('rf', rf), ('svc', svc), ('lr', rl), (\"knn\",knn),(\"dt\",dt)], final_estimator = gb).fit(X_train,y_train)\n",
    "print(\"sclf test score :\", sclf.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a11d519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc test score : 0.7932960893854749\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(base_estimator=gb,n_estimators=400)\n",
    "abc.fit(X_train,y_train)\n",
    "print(\"abc test score :\",abc.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118fd573",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63b20f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#une fonction permettant de réuidre le learning rate en fonction de l'évolution de la \"val_accuracy\"\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reducelr = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                        min_delta = 0.001,\n",
    "                        patience = 10,\n",
    "                        factor = 0.5, \n",
    "                        cooldown = 5,\n",
    "                        verbose = 1)\n",
    "\n",
    "#une fonction permettant de stoper l'entrainement si l'évolution de la \"val_accuracy\" ne depasse plus un certain seuil\n",
    "from tensorflow.keras.callbacks import EarlyStopping \n",
    "earlystop = EarlyStopping(monitor = 'val_accuracy',\n",
    "                    min_delta = 0.0001,\n",
    "                    patience = 50,\n",
    "                    verbose = 1,\n",
    "                    restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd8bf18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               9728      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184,321\n",
      "Trainable params: 184,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense ,  Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#creation du model avec 2 couche Dense\n",
    "model = Sequential()\n",
    "model.add(Input(shape = X_train.shape[1]))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"tanh\"))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(32, activation=\"tanh\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086bd5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "12/12 [==============================] - 1s 19ms/step - loss: 0.5636 - accuracy: 0.6872 - val_loss: 0.5280 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4665 - accuracy: 0.8102 - val_loss: 0.5068 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8295 - val_loss: 0.5027 - val_accuracy: 0.7762 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8260 - val_loss: 0.5022 - val_accuracy: 0.7762 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3910 - accuracy: 0.8295 - val_loss: 0.5020 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8471 - val_loss: 0.4860 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3584 - accuracy: 0.8506 - val_loss: 0.5356 - val_accuracy: 0.7622 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3421 - accuracy: 0.8647 - val_loss: 0.5071 - val_accuracy: 0.7692 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3304 - accuracy: 0.8647 - val_loss: 0.5518 - val_accuracy: 0.7413 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3437 - accuracy: 0.8647 - val_loss: 0.5563 - val_accuracy: 0.7552 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8594 - val_loss: 0.5407 - val_accuracy: 0.7413 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3189 - accuracy: 0.8647 - val_loss: 0.5739 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Epoch 13/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2487 - accuracy: 0.9000\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3111 - accuracy: 0.8752 - val_loss: 0.5459 - val_accuracy: 0.7273 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2964 - accuracy: 0.8840 - val_loss: 0.5695 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
      "Epoch 15/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2840 - accuracy: 0.8840 - val_loss: 0.5999 - val_accuracy: 0.7413 - lr: 5.0000e-04\n",
      "Epoch 16/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8805 - val_loss: 0.5917 - val_accuracy: 0.7413 - lr: 5.0000e-04\n",
      "Epoch 17/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2802 - accuracy: 0.8805 - val_loss: 0.6282 - val_accuracy: 0.7133 - lr: 5.0000e-04\n",
      "Epoch 18/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8840 - val_loss: 0.6190 - val_accuracy: 0.7273 - lr: 5.0000e-04\n",
      "Epoch 19/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.8928 - val_loss: 0.6329 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 20/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.8928 - val_loss: 0.6551 - val_accuracy: 0.7343 - lr: 5.0000e-04\n",
      "Epoch 21/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2858 - accuracy: 0.8787 - val_loss: 0.6713 - val_accuracy: 0.6993 - lr: 5.0000e-04\n",
      "Epoch 22/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2703 - accuracy: 0.8840 - val_loss: 0.6355 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 23/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2716 - accuracy: 0.8822 - val_loss: 0.6572 - val_accuracy: 0.7483 - lr: 5.0000e-04\n",
      "Epoch 24/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2654 - accuracy: 0.8946 - val_loss: 0.6550 - val_accuracy: 0.6993 - lr: 5.0000e-04\n",
      "Epoch 25/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.8893 - val_loss: 0.6887 - val_accuracy: 0.7343 - lr: 5.0000e-04\n",
      "Epoch 26/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.8963 - val_loss: 0.6766 - val_accuracy: 0.7203 - lr: 5.0000e-04\n",
      "Epoch 27/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.2798 - accuracy: 0.8600\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2624 - accuracy: 0.8928 - val_loss: 0.7108 - val_accuracy: 0.7133 - lr: 5.0000e-04\n",
      "Epoch 28/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2473 - accuracy: 0.8910 - val_loss: 0.7268 - val_accuracy: 0.7133 - lr: 2.5000e-04\n",
      "Epoch 29/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2421 - accuracy: 0.8963 - val_loss: 0.7155 - val_accuracy: 0.7203 - lr: 2.5000e-04\n",
      "Epoch 30/200\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2409 - accuracy: 0.8963 - val_loss: 0.7080 - val_accuracy: 0.7343 - lr: 2.5000e-04\n",
      "Epoch 31/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2419 - accuracy: 0.9016 - val_loss: 0.7232 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 32/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.8946 - val_loss: 0.7399 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 33/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2349 - accuracy: 0.9033 - val_loss: 0.7383 - val_accuracy: 0.7203 - lr: 2.5000e-04\n",
      "Epoch 34/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2339 - accuracy: 0.8998 - val_loss: 0.7617 - val_accuracy: 0.7133 - lr: 2.5000e-04\n",
      "Epoch 35/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2323 - accuracy: 0.8998 - val_loss: 0.7608 - val_accuracy: 0.7343 - lr: 2.5000e-04\n",
      "Epoch 36/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2343 - accuracy: 0.8981 - val_loss: 0.7666 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 37/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2326 - accuracy: 0.9033 - val_loss: 0.7808 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 38/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2304 - accuracy: 0.9033 - val_loss: 0.7685 - val_accuracy: 0.7203 - lr: 2.5000e-04\n",
      "Epoch 39/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.8998 - val_loss: 0.7933 - val_accuracy: 0.7203 - lr: 2.5000e-04\n",
      "Epoch 40/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2348 - accuracy: 0.9033 - val_loss: 0.7741 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 41/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1649 - accuracy: 0.9400\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2357 - accuracy: 0.8963 - val_loss: 0.7918 - val_accuracy: 0.7273 - lr: 2.5000e-04\n",
      "Epoch 42/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2222 - accuracy: 0.9016 - val_loss: 0.7987 - val_accuracy: 0.7203 - lr: 1.2500e-04\n",
      "Epoch 43/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2240 - accuracy: 0.9033 - val_loss: 0.8022 - val_accuracy: 0.7203 - lr: 1.2500e-04\n",
      "Epoch 44/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.9069 - val_loss: 0.8017 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 45/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.8893 - val_loss: 0.8079 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 46/200\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2236 - accuracy: 0.9121 - val_loss: 0.8074 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 47/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9104 - val_loss: 0.8200 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 48/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9051 - val_loss: 0.8157 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 49/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9069 - val_loss: 0.8239 - val_accuracy: 0.6993 - lr: 1.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2213 - accuracy: 0.9051 - val_loss: 0.8462 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 51/200\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.2166 - accuracy: 0.9086 - val_loss: 0.8331 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 52/200\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2163 - accuracy: 0.9051 - val_loss: 0.8287 - val_accuracy: 0.7133 - lr: 1.2500e-04\n",
      "Epoch 53/200\n",
      " 1/12 [=>............................] - ETA: 0s - loss: 0.1861 - accuracy: 0.9400Restoring model weights from the end of the best epoch: 3.\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.2160 - accuracy: 0.9069 - val_loss: 0.8376 - val_accuracy: 0.7063 - lr: 1.2500e-04\n",
      "Epoch 53: early stopping\n"
     ]
    }
   ],
   "source": [
    "#entrainement du modèle\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "model_history = model.fit (X_train, y_train, epochs = 200, batch_size = 50, validation_split = 0.2, callbacks= [reducelr,earlystop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
